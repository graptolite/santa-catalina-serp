{"cells":[{"cell_type":"markdown","id":"8a7d85c9-1ae4-4c9c-be0b-f0950f31f6a2","metadata":{},"source":"Reflector Area Processing - Tests of Homogeneity\n================================================\n\n"},{"cell_type":"markdown","id":"21213dc5-dbbd-4888-96f0-709b4004f297","metadata":{},"source":["This analysis will be for the 10x10 px dilation-erosion kernal, which was identified as the optimal size in `../section-scans-validation/further-analysis.org`. Contours are from `../section-scans-refined/contours-modified-10/`.\n\n"]},{"cell_type":"code","execution_count":1,"id":"3c1aaabf-71ac-4fe6-a6bb-413dd37a5b6c","metadata":{},"outputs":[],"source":["FORCE_OVERWRITE = False\n\n####################################\n# Don't change anything below here #\n####################################\ndilate_erode = 10\n\nif dilate_erode:\n    file_prepend = f\"modified-{dilate_erode}\"\nelse:\n    file_prepend = \"unmodified\"\n\nimport os\nimport sys\nsys.path.insert(0,os.path.join(\"..\",\"section-scans-full\"))\n# General util funcs as detailed in ../section_scans-example/working.org (or its derivatives)\nfrom util_funcs import *\n\ndef save_figure(path):\n    ''' Check if an image containing figure output already exists, otherwise save that figure.\n\n    path (string) : path to save the figure to.\n\n    returns None\n    '''\n    if not os.path.exists(path) or FORCE_OVERWRITE:\n        plt.savefig(path,bbox_inches=\"tight\")\n    return\n\nimport pandas as pd\nimport json\n\n# Degree of alteration assigned to each section.\nalteration_degree = {\"M04\":0,\n                     \"07A\":0,\n                     \"M08\":0,\n                     \"06C\":1,\n                     \"M07B1\":1,\n                     \"M07B2\":1,\n                     \"M01\":1,\n                     \"M02\":2}\n\n# Text descriptions for each level of alteration.\nalteration_desc = {0:\"Partly\",\n                   1:\"Heavily\",\n                   2:\"V. Heavily\"}"]},{"cell_type":"markdown","id":"32ca4099-b6a7-48ec-8fd4-3ffa9224cc97","metadata":{},"source":["## Section Scan Study Areas\n\n"]},{"cell_type":"markdown","id":"2e1a11e4-eaea-424d-803d-e9b70dbf60d3","metadata":{},"source":["Homogeneity tests require knownledge of the full image dimensions (i.e. not convex hull dimensions), which are non-changing and so can be saved in nonvolatile storage.\n\n"]},{"cell_type":"code","execution_count":1,"id":"307968c9-3dfd-4d28-a451-08daf9c950c7","metadata":{},"outputs":[],"source":["# Folder containing thresholded samples (stored as .png).\n# Note: folder linking has been used - this is not the real path.\nsamples_dir = os.path.join(\"..\",\"..\",\"DATASETS\",\"RL_scans\")\n# Load thresholded sample filenames from the folder.\n# Ignore the manually investigated images (for sample M07B1).\nsamples = [f for f in os.listdir(samples_dir) if f.endswith(\".png\") and \"-\" not in f]\nif not os.path.exists(\"scan_dimensions.csv\") or FORCE_OVERWRITE:\n    # Extract image dimensions to dictionary.\n    img_dimensions = {sample.replace(\".png\",\"\"):(lambda dim :\n                                                 {\"h\":dim[0],\"w\":dim[1]})(cv2.imread(os.path.join(samples_dir,sample)).shape)\n                      for sample in samples}\n    # Same image dimensions to csv.\n    pd.DataFrame.from_dict(img_dimensions,orient=\"index\").to_csv(\"scan_dimensions.csv\")"]},{"cell_type":"markdown","id":"d7246ef1-7491-44cd-bad7-cfc4b79badb6","metadata":{},"source":["## Homogeneity Testing\n\n"]},{"cell_type":"markdown","id":"279f6729-c215-454a-9092-7f183abffbe7","metadata":{},"source":["Using the \"Crystal density method\" described on p. 41 (Kretz 1969).\n\n"]},{"cell_type":"code","execution_count":1,"id":"a0eadcc0-b1b7-41f7-836e-5507f80e1898","metadata":{},"outputs":[],"source":["from shapely.geometry import Polygon\nimport shapely as shp\nfrom matplotlib import path\nimport scipy.stats as sps\n\n# Critical p value below which homogeneity is rejected.\np_crit = 0.05\n\n# Load scan dimensions.\nscans_df = pd.read_csv(\"scan_dimensions.csv\",index_col=0)\n\n# Iterate through samples for consideration.\nfor sample in samples:\n    # Load sample dimensions.\n    sample_dimensions = scans_df.loc[sample.replace(\".png\",\"\")]\n    # Isolate height and width.\n    h,w = sample_dimensions.to_numpy()\n\n    # Load cv2-specification reflector patch definitions.\n    larger_contours = np.load(os.path.join(\"..\",\"section-scans-refined-full\",f\"contours-{file_prepend}\",f\"{sample}-larger.npy\"),allow_pickle=True)\n    # Compute centroids of each reflector patch, making sure they're downscaled appropriately.\n    centroids = np.array([np.array(Polygon(c[:,0,:]).centroid.xy).T[0] for c in larger_contours])/2\n    # Fix y-coordinate definition\n    centroids[:,1] = h - centroids[:,1]\n\n    # Define quadrant polygons.\n    bottom_left = Polygon([(0,0),(0,h/2),(w/2,h/2),(w/2,0)])\n    locations = dict(bottom_left = bottom_left,\n                     bottom_right = shp.transform(bottom_left,lambda v : v + [w/2,0]),\n                     top_left = shp.transform(bottom_left,lambda v : v + [0,h/2]),\n                     top_right = shp.transform(bottom_left,lambda v : v + [w/2,h/2]))\n\n    # Define list in which to store grain counts in each quadrant.\n    counts = []\n    # Iterate through the quadrants.\n    for loc,polygon in locations.items():\n        # Construct matplotlib polygon.\n        p = path.Path(list(zip(*polygon.exterior.xy)))\n        # Determine whether each centroid is within the polygon or not.\n        spatial_filter = p.contains_points(centroids)\n        # Count the number of centroids inside the polygon.\n        n_items = sum(spatial_filter)\n        # Save the count.\n        counts.append(n_items)\n    # Perform chi squared test.\n    res = sps.chisquare(counts)\n    # Isolate p value.\n    p = res.pvalue\n    # Determine outcome of test.\n    if p < p_crit:\n        outcome = \"inhomogeneous\"\n    else:\n        outcome = \"homogeneous\"\n    # Display outcome of test.\n    sample_name = sample.replace(\".png\",\"\")\n    print(f\"{sample_name} {outcome} at {1-p_crit} level of significance (observed p={p:.3g})\")\n\n    # # For validation purposes:\n    # # Visualising the quadrants.\n    # [plt.plot(*p.exterior.xy,alpha=0.5) for p in locations.values()]\n    # # Visualising the centroid locations.\n    # plt.scatter(centroids[:,0],centroids[:,1],s=0.1)\n    # plt.gca().set_aspect(\"equal\")\n    # plt.show()"]},{"cell_type":"markdown","id":"30e1fa62-50b2-4276-bc3d-2b48ee37b58f","metadata":{},"source":["All section scans except M04 are found to be inhomogeneous.\n\n-   Therefore grain distributions can't be assumed random for sections except M04.\n\nIn Kretz 1969, inhomogeniety was mitigated by cropping the scan, but this is not as easy to do with the serpentinite scans, and so the presence of inhomogeniety will remain a broad-scale observation rather than something that's to be mitigated.\n\n-   This also suggests that the scans cover too small an area, hence future work may benefit from whole-section scans (as long as the equipment for that is available).\n\nNearest-neighbour testing can be used to determine whether distributions are random as well, and should conclude that all scans except M04 have non-random reflector distributions.\n\n"]},{"cell_type":"markdown","id":"f6f31140-12a5-4d67-9244-b25cd328d1cc","metadata":{},"source":["## Nearest-Neighbour Distance\n\n"]},{"cell_type":"markdown","id":"fd02bdb0-03c1-4883-9b5e-2846709ef7fb","metadata":{},"source":["Assuming randomly distributed grains, the observed mean nearest-neighbour distance can be compared to the expected nearest-neighbour distance (Kretz 1969 p. 50):\n\n\\begin{align}\n\\Gamma_E &= \\frac{1}{2\\sqrt{N/A}}\\\\\n\\Gamma_O &= \\frac{\\Sigma\\Gamma}{N}\n\\end{align}\n\nWhere $\\Gamma$ is nearest-neighbour distance (subscript $E$ - expected, $O$ - observed), $N$ number of grains in $A$, $A$ total area considered.\n\n\\begin{equation}\nc = \\frac{N(\\Gamma_A-\\Gamma_O)}{0.26136\\sqrt{A}}\n\\end{equation}\n\nWhere $c$ is the standard variate of the normal curve, with $|c| > 1.96$ suggesting non-randomness at a 0.95 level of significance.\n\nPixels will be used as the distance measurement here for simplicity.\n\n"]},{"cell_type":"code","execution_count":1,"id":"0f0bbf89-4da9-4c29-b70c-54855502db60","metadata":{},"outputs":[],"source":["from scipy.spatial import KDTree\n\nc_crit = 1.96\n\nfor sample in samples:\n    # Load sample dimensions.\n    sample_dimensions = scans_df.loc[sample.replace(\".png\",\"\")]\n    h,w = sample_dimensions.to_numpy()\n\n    # Load cv2-specification reflector patch definitions.\n    larger_contours = np.load(os.path.join(\"..\",\"section-scans-refined-full\",f\"contours-{file_prepend}\",f\"{sample}-larger.npy\"),allow_pickle=True)\n    # Compute centroids of each reflector patch, making sure they're downscaled appropriately.\n    centroids = np.array([np.array(Polygon(c[:,0,:]).centroid.xy).T[0] for c in larger_contours])/2\n    # Fix y-coordinate definition\n    centroids[:,1] = h - centroids[:,1]\n    # Construct KD tree using centroids for nearest-neighbour searching.\n    tree = KDTree(centroids)\n    # Compute nearest-neighbour distances for each reflector's centroid.\n    Gamma = [tree.query(c,2)[0][1] for c in centroids]\n    # Compute scan area.\n    A = h * w\n    # Get number of grains.\n    N = len(centroids)\n    # Compute expected \"average\" nearest-neighbour distance.\n    Gamma_E = 1/(2 * np.sqrt(N/A))\n    # Compute observed \"average\" nearest-neighbour distance.\n    Gamma_O = sum(Gamma)/N\n    # Compute standard variate of the normal curve.\n    c = (N * (Gamma_O - Gamma_E))/(0.26136 * np.sqrt(A))\n    # Determine outcome.\n    if abs(c) < c_crit:\n        outcome = \"random\"\n    else:\n        outcome = \"not random\"\n    # Display outcome.\n    sample_name = sample.replace(\".png\",\"\")\n    print(f\"{sample_name} {outcome} at 0.95 level of significance (observed c={c:.3g})\\n\\tGamma_E={Gamma_E}, Gamma_O={Gamma_O}\")"]},{"cell_type":"markdown","id":"39694451-4a8d-4225-b14d-1c83d7aa140a","metadata":{},"source":["Nearest-neighbour distances suggest none of these scans contain randomly distributed reflector grains (not even M04).\n\nSince observed mean nearest-neighbour distances are lower than observed, it can be concluded that grains tend to be more clustered than a random (spatial) distribution of grains. I.e. grains are often close together (but not touching).\n\n-   This matches with visual inspections of the section scans, which suggest that reflectors are often found in dense patches.\n\n"]}],"metadata":{"org":null,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":5}
