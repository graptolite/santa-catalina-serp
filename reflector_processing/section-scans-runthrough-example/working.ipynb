{"cells":[{"cell_type":"markdown","id":"acd2a310-4112-416f-a624-e5bb5fa7d9ca","metadata":{},"source":"Microphotograph Stitching and Reflector Area Processing for one Example\n=======================================================================\n\n"},{"cell_type":"code","execution_count":1,"id":"48d3992a-71fc-4d28-a2bf-3beb34ed4ca9","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[17]:"}],"source":["FORCE_OVERWRITE = False\ndef save_figure(path):\n    ''' Check if an image containing figure output already exists, otherwise save that figure.\n\n    path (string) : path to save the figure to.\n\n    returns None\n    '''\n    if not os.path.exists(path) or FORCE_OVERWRITE:\n        plt.savefig(path)\n    return"]},{"cell_type":"markdown","id":"68249348-7efd-4fcd-a0b9-f57d0f0f44a0","metadata":{},"source":["Note: this notebook saves and reads numpy save files **via pickle**.\n\nThis analysis was inspired by initial hypotheses described in figure [3](#orge1eb677).\n\n![img](./imgs/hypotheses.png \"Initial hypotheses for what grain size distributions could mean.\")\n\nThough many functions represent generalised operations, most are described/named in such a way to fit the context of the specific analysis. For code brevity (at the cost of robustness), input verification in functions is also mostly skipped. Therefore, this notebook is designed to demonstrate the specific analysis performed.\n\n"]},{"cell_type":"markdown","id":"dedc5ee1-6a33-4adc-b9ec-48d72bb91879","metadata":{},"source":["## Stitching a Section Scan\n\n"]},{"cell_type":"markdown","id":"c5ec2687-cb49-418a-af43-603488a1ff28","metadata":{},"source":["Note: since the stitching method has little effect on the final results of this analysis, the code is not analysed in detail here. Also, similar to it's actual usage during the project, the code does not become fully automated, requiring manual changes to the sample name (folder) in the function `stitch_full` since the samples were photographed over multiple days. Stitched scans already exist in `./DATASETS/RL_scans/`, so this section is included mostly for completeness.\n\nDue to a lack of Reflected-Light section scanning microscope, manual photography followed by semi-automated image stitching (dependent on `Hugin` - [https://hugin.sourceforge.io/>](https://hugin.sourceforge.io/>)and the Hugin Scripting Interface `hsi`; tested/working on Debian 11, but with `hsi` install failed on Debian 12) was necessary to create Reflected-Light scans for further processing.\n\nThis involved:\n\n1.  Sequential photographing of the section along a path that would cover an area in a snake-path without changing zoom, where there would be overlap between subsequent photos (in a \"column\") as well as overlap between \"columns\" of photos (figure [18](#org6235d7b)).\n    -   These photographs must be taken at constant illumination and exposure, with no change in the white/black balance of the image. It may be necessary to disable auto white/black balance.\n    -   Gamma may need to be changed to produce a significant contrast between reflective and non-reflective grains.\n    -   Camera lens distortion should be negligible such as mosaic stitching is assumed later (i.e. sequential images are just transformed on a 2D plane relative to each other).\n    -   The sequential nature of the photos must be reflected in their filenames. The files must be named in the format `image<4-digit id>.<file extension>`.\n2.  If necessary, converting the images into .jpg format.\n3.  Organising the photographs into multiple folders, each containing just one column of photos (with column folder name format `col<numerical id>`). An example folder structure:\n    -   `<Sample Name>`\n        -   `col1`\n        -   `col2`\n        -   `col3`\n        -   *etc.*\n4.  Running the image stitcher below.\n    -   Note: the final output file won't be named after the sample - it's large size means it isn't the most suitable for long term storage so isn't prioritised as such.\n\n![img](./imgs/section-scanning.png \"Taking pictures for a larger area than one single frame of view using a snaking path (arrow shows direction of sequential photography). Note: 'column' refers to a collection of photos taken sequentially where all photos lie roughly on one axis. The size of the overlapping area doesn't need to be the same for all neighbouring images, and should be big enough that there are common features that can be seen visually.\")\n\n"]},{"cell_type":"code","execution_count":1,"id":"30c23288-f12f-4841-aaa0-66ae6786bb6a","metadata":{},"outputs":[],"source":["# Change sample to the full folder path of the relevant sample\nsample = \"stitch-eg\""]},{"cell_type":"code","execution_count":1,"id":"7c9665b2-159d-44ff-a06e-f33141ef285c","metadata":{},"outputs":[],"source":["try:\n    # IMAGE STITCHER\n    from image_stitcher import stitch_full\n    do_convert_output = True\n    stitch_full(sample,do_convert_output)\n    print(\"Stitching completed\")\nexcept:\n    print(\"Stitching failed\")"]},{"cell_type":"markdown","id":"ff5c1c12-917d-4372-8ca6-53f572dbac37","metadata":{},"source":["## Extracting Reflectors\n\n"]},{"cell_type":"markdown","id":"7db84419-5256-4265-9691-fe52124283cc","metadata":{},"source":["Open one of the scan files (either original/non-converted or converted) in GIMP then use thresholding to isolate reflectors from the rest of the scan:\n\n1.  Open the Threshold dialogue: Colours &rarr; Threshold\n2.  Adjust the critical threshold value until the reflectors are all selected for (white in black background) without too much noise (noise in the form of isolated pixels is fine as that can be filtered out later by considering areas above a certain number of pixels). Using the \"Split view\" functionality can help.\n3.  Add an alpha channel to the image.\n4.  Select by colour &rarr; select all black pixels and delete.\n5.  Export the image as a .png file with **alpha channel preserved**.\n\nThis processing was applied to the example output and saved to `./stitch-eg/stitch-eg.png`.\n\n"]},{"cell_type":"markdown","id":"7de8739b-3c03-462f-b08c-1fde524ee17b","metadata":{},"source":["## Automated Reflector Processing\n\n"]},{"cell_type":"markdown","id":"ca1510fb-1d8d-4bba-b662-b707b8fd7d5d","metadata":{},"source":["### Spatial Description of Reflectors\n\n"]},{"cell_type":"markdown","id":"18f39ed9-b32e-441b-b74d-ab24050d6ac4","metadata":{},"source":["Reflector shapes are extracted as contours (using OpenCV methods) to permit further analysis. Some basic attempt at filling in gaps between grains is applied by default (can be disabled by setting `expand_erode` to `False`) to reduce the effect of small fractures or image-artefact gaps between reflectors. This is done through a dilate followed by erode (to prevent areas growing too much in size).\n\n"]},{"cell_type":"code","execution_count":1,"id":"41df920f-65f5-4ed1-a09f-5c8b251db7c6","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[8]:"}],"source":["import cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.ndimage import binary_fill_holes\nimport pandas as pd\nimport os\n\ndef reflector_processing(img_path,dilate_erode=False):\n    ''' Extract and save the contours of a thresholded scan. Both the \"real size\" (slightly smaller than actual reflector patches) and enlarged (extracted from image that's been scaled up by a factor of 2) contours are extracted and saved, which permits patch area computation.\n\n    img_path (string) : path to thresholded scan (image)\n    expand_erode (bool) : whether to dilate then erode the image in an attempt to join together reflectors separated by small distances (e.g. fractures)\n\n    returns None\n    '''\n    # Load image as BGRA image.\n    img = cv2.imread(img_path,cv2.IMREAD_UNCHANGED)\n    # Isolate alpha channel.\n    binary_img = alpha_channel = img[:,:,3]\n\n    if dilate_erode:\n        # Fill any holes within reflector patches.\n        # Must be uint8 for use by cv2.dilate\n        enclaves_filled = binary_fill_holes(binary_img).astype(np.uint8)\n        # Attempt to fill fractures to bring grains back to original, unfractured sizes by dilating ; subjective.\n        kernel = np.ones((20,20),np.uint8)\n        unfrag = cv2.dilate(enclaves_filled,kernel,iterations=1)\n        enclaves_filled = binary_fill_holes(unfrag).astype(np.uint8)\n        # Attempt to remove extra material added from previous step.\n        final_img = cv2.erode(enclaves_filled,kernel)\n    else:\n        final_img = binary_img.astype(np.uint8)\n\n    # Even when drawing *external* contours, the raster nature of the array is ignored:\n    #   -----\n    # 1 |x|x|\n    #   -----\n    # 0 |x|x|\n    #   -----\n    #    0 1\n    # Becomes [0,0],[1,1], such that the area is 1.\n    # This is fixed by determining the number of pixels the patch contour covers in a 2x scaled up image, then performing the operation (larger_contour_areas + 1 - 2 * contour_areas)/2 to find the number of pixels in the original patch.\n\n    larger_img = cv2.resize(final_img,tuple(np.array(final_img.shape)*2)[::-1],interpolation=cv2.INTER_NEAREST)\n    # Extract non-zero areas; note cv2.CHAIN_APPROX_NONE prevents simplification of the vector definition of raster patches.\n    contours,_ = cv2.findContours(final_img,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n    larger_contours,_ = cv2.findContours(larger_img,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n\n    # Save the contour definitions for future processing.\n    np.save(f\"{img_path}.npy\",np.array(contours,dtype=object))\n    np.save(f\"{img_path}-larger.npy\",np.array(larger_contours,dtype=object))\n    return"]},{"cell_type":"markdown","id":"8f22f87b-7ead-4756-8977-f5bd81ab0ed1","metadata":{},"source":["The thresholded images (all in .png format) should all be moved into one folder, whose path should be assigned to `rl_scan_folder` below. This folder should not contain any other .png files.\n\n"]},{"cell_type":"code","execution_count":1,"id":"56ff8a54-8fcc-41c0-9bf2-c4b2e1508cff","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[41]:"}],"source":["# Folder containing all of the thresholded scans.\nrl_scan_folder = \"stitch-eg\"\n# List all files in the folder.\nbasefiles = os.listdir(rl_scan_folder)\n# Can overwrite this by specifying which files in the folder to process:\n# basefiles = [\"manual-M07B1-threshold.png\",\"manual-M07B1-threshold-redrawn.png\"]\n\n# List only the .png files, which represent the thresholded scans.\nimgs = [f for f in basefiles if f.endswith(\".png\")]\n\n# Process all thresholded scans where necessary.\nfor img in imgs:\n    if not os.path.exists(os.path.join(rl_scan_folder,f\"{img}.npy\")) or FORCE_OVERWRITE:\n        reflector_processing(os.path.join(rl_scan_folder,img))"]},{"cell_type":"markdown","id":"f9f88e26-0990-4592-95a0-8b56781d3e65","metadata":{},"source":["### Reflector Parameters\n\n"]},{"cell_type":"markdown","id":"a2c8a3c0-4c16-4930-8a66-0399848e53f8","metadata":{},"source":["The reflector patch areas ($A_p$) are a function of the areas enclosed by the smaller ($A_l$) and larger contours ($A_l$), with all units in pixels:\n\n\\begin{equation}\nA_p = \\frac{A_l + 1 - 2 A_s}{2}\n\\end{equation}\n\n"]},{"cell_type":"code","execution_count":1,"id":"b32cf8bf-5d5a-4257-9c90-0afe221ee904","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[44]:"}],"source":["def find_areas(contours,larger_contours,pix2mm=None):\n    ''' Compute patch areas using \"small\" and \"large\" contours and then convert to mm^2 if necessary.\n\n    contours : list of \"small\" contours with vertices in pixel units\n    larger_contours : list of \"large\" contours with vertices in pixel units\n    pix2mm (numerical) : conversion factor between pixels to millimeters\n\n    returns patch_areas : list of patch areas\n    units : the units that the returned patch areas are in\n    '''\n    contour_areas = np.array(list(map(cv2.contourArea,contours)))\n    larger_contour_areas = np.array(list(map(cv2.contourArea,larger_contours)))\n    patch_areas = (larger_contour_areas + 1 - 2 * contour_areas)/2\n    if pix2mm:\n        patch_areas = np.array(patch_areas) * (pix2mm**2)\n        units = \"mm\"\n    else:\n        units = \"px\"\n    return patch_areas,units"]},{"cell_type":"markdown","id":"82127001-31b4-4121-bfc2-4bb66848f6e8","metadata":{},"source":["The 10x zoom on the microscope combined with the image resolution means that 1000 pixels is ~1 mm. This scaling factor can be used to convert pixel areas into mm<sup>2</sup> areas. This is confirmed by figure [2](#org6e19483), where the 100 micron scale bar is ~100 px long. Due to the effectively-common slide thicknesses, all section were effectively photographed at the same zoom with the same pixel resolution, hence this scale factor is assumed universal for all the scans.\n\n![img](./imgs/generic-scale-m01.jpg \"Image taken at 10x zoom for the purpose of defining the scale.\")\n\n"]},{"cell_type":"code","execution_count":1,"id":"aa5468a8-5636-4285-8b9e-73cbb2aa49c8","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[6]:"}],"source":["pix2mm = 0.001 # scale factor from pixels to mm i.e. how many mm per pixel"]},{"cell_type":"markdown","id":"5ddad7ae-af11-4f8e-90ff-24aa161ccbf8","metadata":{},"source":["Contours were saved by the previous section into .npy files, which can be reloaded into the active workspace as required.\n\n"]},{"cell_type":"code","execution_count":1,"id":"7021e250-450a-4893-b20f-8d037a3751ca","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[10]:"}],"source":["def load_contours(sample,basepath):\n    ''' Load the \"small\" and \"large\" contours from .npy files and filter to just contours with \"small\" contour area above a threshold.\n\n    sample (string) : name of the sample used in the .npy data filenames\n    basepath (string) : folder containing the .npy data files\n\n    returns contours : array of \"small\" contours\n    larger_contours : array of \"large\" contours\n    '''\n    contours = np.load(os.path.join(basepath,f\"{sample}.png.npy\"),allow_pickle=True)\n    larger_contours = np.load(os.path.join(basepath,f\"{sample}.png-larger.npy\"),allow_pickle=True)\n    return contours,larger_contours"]},{"cell_type":"markdown","id":"0b3d0b0c-1c6c-404b-a0a5-e2fa5f390a0a","metadata":{},"source":["In order to reduce the effect of fine, grainy noise (from the GIMP thresholding extraction), a filter removing reflectors (both apparent/noise and real) with *patch* areas below a certain threshold can be applied when loading contours.\n\n-   The minimum patch area was set to 5 px for all samples in the actual analysis, and will also be used in this example run.\n\nIn order to avoid issues with heterogeneity in the spatial distribution of reflectors, especially in 3D (e.g. \\citealp{Palin2016}, and under the assumption that coarser grained populations are most susceptible to uncertainty associated with this heterogeneity (the opposite being mentioned in section 5 final paragraph of \\citealp{Palin2016}), a maximum area is also set for the patches that are considered for further analysis. This maximum value was set at 0.05 mm<sup>2</sup> in the actual analysis based on roughly where the distribution of grain areas stopped seeming well sampled as well as being a relatively \"round\" number.\n\n-   Removal of grains larger than 0.05 mm<sup>2</sup> **is** reflected in the convex hull (study) area computed below (as grains that are filtered out aren't considered in further analysis).\n-   The largest reflector area is still captured in case it is useful down the line.\n\n"]},{"cell_type":"code","execution_count":1,"id":"689eb11e-ed32-4b27-81fd-9642c905a20d","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[45]:"}],"source":["def construct_minmax_filter(arr,min_val=None,max_val=None):\n    ''' Create min-max boolean filter using an array of values.\n\n    arr (list of numericals) : array of values\n    min_val (numerical) : minimum end of filter\n    max_val (numerical) : maximum end of filter\n\n    returns minmax_filter (list of bool) : boolean filter applicable to arr\n    '''\n    # If no min_val provided, set to the minimum in the array (i.e. no minimum filtering)\n    if min_val == None:\n        min_val = min(arr)\n    # If no max_val provided, set to the maximum in the array (i.e. no maximum filtering)\n    if max_val == None:\n        max_val = max(arr)\n    minmax_filter = np.logical_and(arr <= max_val,arr >= min_val)\n    return minmax_filter\n\ndef list_of_list_filter(list_of_list,bool_filter):\n    ''' Filter a list of list-like objects by a top-level boolean filter.\n\n    list_of_list : list of list-like objects\n    bool_filter : top-level boolean filter\n\n    returns : list of list-like objects\n    '''\n    return [l[0] for l in zip(list_of_list,bool_filter) if l[1]]\n\ncontours,larger_contours = load_contours(sample,rl_scan_folder)\npatch_areas,unit = find_areas(contours,larger_contours,pix2mm)\n\n# Find the largest grain area before filtering.\nlargest_grain = max(patch_areas)\n\n# Size filtering.\nmin_reflector_area = 5 * pix2mm**2 # mm2\nmax_reflector_area = 0.05 # mm2\n\nsize_filter = construct_minmax_filter(patch_areas,min_reflector_area,max_reflector_area)\npatch_areas = patch_areas[size_filter]\n# Filter for just the relevant contours.\ncontours = list_of_list_filter(contours,size_filter)\nlarger_contours = list_of_list_filter(larger_contours,size_filter)"]},{"cell_type":"markdown","id":"ad46ac57-400b-468c-810f-aad813862814","metadata":{},"source":["Another important bit of information that can be extracted from these contours is the minimum area studied, which is the convex hull of the contours.\n\n"]},{"cell_type":"code","execution_count":1,"id":"4104532a-d57f-4352-91a9-fd81f03e447b","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[33]:"}],"source":["from scipy.spatial import ConvexHull\nfrom shapely.geometry import Polygon\n\ndef area_convhull_polygons(contours):\n    ''' Determine the convex hull area in the same units as used to define the coordinates of the polygon.\n\n    contours : list of contour polygons defined by their vertices\n\n    returns area (numerical) : convex hull area of the list of contour polygons\n    '''\n    # Flatted the polygons such that the convex hull is for the collection of polygons vertices.\n    points = []\n    for c in contours:\n        points += c[:,0].tolist()\n    points = np.array(points)\n    # Determine the convex hull of the polygon vertices.\n    hull = ConvexHull(points)\n    # Extract the points defining the hull's vertices.\n    polygon = points[hull.vertices]\n    # Find the area of the convex hull as defined by its vertices.\n    area = Polygon(polygon).area\n    return area"]},{"cell_type":"markdown","id":"15202c4d-2474-4cf2-a9b4-2a804c6171ef","metadata":{},"source":["Since the contours are defined in units of pixels, a pixel to mm<sup>2</sup> conversion must be applied.\n\n"]},{"cell_type":"code","execution_count":1,"id":"ee8ed653-d139-4059-b94c-832109cc6e84","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[34]:"}],"source":["area_studied = area_convhull_polygons(contours) * (pix2mm**2)"]},{"cell_type":"markdown","id":"cb46784d-f17a-4a75-bd9c-2c53acfa3284","metadata":{},"source":["The `patch_areas` and `area_studied` are both now in the units of mm<sup>2</sup> and constitute the \"area\" data, which can be saved in one .json file. In the actual analysis, this .json file aggregated area data for all sections of interest.\n\n"]},{"cell_type":"code","execution_count":1,"id":"7c482309-899c-48c3-85b5-a017b70f6db0","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[35]:"}],"source":["import json\n\n# Demonstration of data structure used in the actual analysis (iterating through samples)\nareas_data = dict()\nareas_data[sample] = dict()\nareas_data[sample][\"patch_areas\"] = list(patch_areas)\nareas_data[sample][\"area_studied\"] = area_studied\n\nif not os.path.exists(\"areas.json\") or FORCE_OVERWRITE:\n    with open(\"areas.json\",\"w\") as outfile:\n        json.dump(areas_data,outfile)"]},{"cell_type":"markdown","id":"dfa31934-3d02-4a0f-95e1-7ca98318b496","metadata":{},"source":["Some other statistics that may be useful to compare between different samples are the number of individual reflectors grains, total area covered by reflectors, the largest reflector area etc. These are captured by another dictionary and saved in a separate .csv file. The degree of alteration is also assigned to each sample in the actual analysis.\n\n-   A curve fit (using an exponential function on log10 of bin counts) to the area distribution of the sample is also produced and added to this dataset.\n-   Note: the curve fit for the example data is not great due to the small dataset.\n\n"]},{"cell_type":"code","execution_count":1,"id":"c6069eec-e762-4b51-92a6-c2098971f14d","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[39]:"}],"source":["from scipy.optimize import curve_fit\n\ndef exp_fit(x,a,b):\n    # Exponential fit function for area distributions.\n    return a * np.exp(b*x)\n\ndef bin_values(values,max_value,n_bins,min_value=0):\n    ''' Bin and count values based on a min-max range and number of bins.\n\n    values (list of numericals) : values to bin\n    max_value (numerical) : maximum bin edge\n    n_bins (int) : number of bins\n    min_value (numerical) : minimum bin edge\n\n    returns counts (list of numerical) : number of values within each bin\n    bins (list of numerical) : bin edges (will be one element longer than bin midpoints)\n    midpoints (list of numerical) : bin midpoints\n    '''\n    # Compute bin edges.\n    bins = np.linspace(min_value,max_value,n_bins+1)\n    # Compute bin midpoints.\n    midpoints = (bins[:-1] + bins[1:])/2\n    # Count values within each bin.\n    counts,_ = np.histogram(values,bins=bins)\n    return counts,bins,midpoints\n\ndef fit_area_distro(counts,midpoints):\n    ''' Determine best fit to distribution of patch areas.\n\n    counts (list of ints) : counts corresponding to each area bin\n    midpoints (list of numericals) : midpoints of area bins\n\n    returns fit_params (list of numericals) : fit parameters\n    '''\n    # Select only datapoints where the bin count is non-zero.\n    nonzero_counts = counts!=0\n    counts = counts[nonzero_counts]\n    midpoints = midpoints[nonzero_counts]\n    # Curve fitting using the exponential distribution function.\n    popt,_ = curve_fit(exp_fit,midpoints,counts)\n    fit_params = popt.tolist()\n    return fit_params\n\ndata = dict()\n\ncounts,_,midpoints = bin_values(patch_areas,0.05,100)\ndata[sample] = {\"convhull\":area_studied, # study area\n                \"n\":len(patch_areas), # number of discrete reflectors after filtering\n                \"total_area\":sum(patch_areas), # area of reflectors after filtering\n                \"largest\":largest_grain, # largest continuous reflector patch area\n                \"curve_fit\":fit_area_distro(counts,midpoints)}\n\nalteration_degree = {\"stitch-eg\":0}\n\nfor sample,sample_data in data.items():\n    try:\n        sample_data[\"alteration\"] = alteration_degree[sample]\n        data[sample] = sample_data\n    except KeyError:\n        pass\n\ndf = pd.DataFrame.from_dict(data,orient=\"index\")\nif not os.path.exists(\"summary.csv\") or FORCE_OVERWRITE:\n    df.to_csv(\"summary.csv\")"]},{"cell_type":"markdown","id":"3ae75c30-55e0-4223-b3e0-6643c5f8fbc6","metadata":{},"source":["## Visualisation\n\n"]},{"cell_type":"markdown","id":"61abfb26-c1c0-4069-b3fc-d08fea56334e","metadata":{},"source":["### Plotting Outputs\n\n"]},{"cell_type":"markdown","id":"f83b8bc4-726f-4ec6-9a9c-5ddab7bc50fb","metadata":{},"source":["#### Area Distribution\n\n"]},{"cell_type":"markdown","id":"22b27030-5cb8-4004-84dd-570396447b0b","metadata":{},"source":["The area distribution can be plotted as a histogram, on which the a fitted continuous distribution can be overlain. Due to a huge range in the counts for equally-spaced ranges, a semilog plot (log y axis) is used.\n\n"]},{"cell_type":"code","execution_count":1,"id":"34ac1322-3af8-4291-b579-20c993a18b7d","metadata":{},"outputs":[],"source":["def plot_area_distribution_and_fit(areas,units,max_area=0.05,n_bins=100):\n    ''' Plot histogram of grain areas and overlay the best fit exponential distribution.\n\n    areas (list of numericals) : grain areas\n    units (string) : units of areas used in plot labelling\n    max_area (numerical) : maximum grain area considered in areas\n    n_bins (int) : number of bins used for fit finding and histogram plotting\n\n    returns fig, ax\n    '''\n    fig,ax = plt.subplots(constrained_layout=True)\n\n    # Compute bin edges.\n    bins = np.linspace(0,max_area,n_bins)\n    # Compute bin midpoints.\n    midpoints = (bins[:-1] + bins[1:])/2\n    # Plot areas histogram.\n    counts,_,_ = ax.hist(areas,bins=bins)\n    # Determine fit parameters.\n    popt = fit_area_distro(counts,midpoints)\n    # Plot fit.\n    ax.plot(midpoints,10**exp_fit(midpoints,*popt))\n    # Display fit.\n    ax.text(1,1,\"$Count = 10**(%.2f \\cdot \\exp(%.2f \\cdot Area))$\" % tuple(popt),transform=ax.transAxes,ha=\"right\",va=\"top\")\n    # Set y axis to log scale.\n    ax.set_yscale(\"log\")\n\n    # Limit axes.\n    ax.set_ylim([1,1.1*max(counts)])\n    ax.set_xlim([0,max_area])\n\n    # Label axes.\n    ax.set_xlabel(f\"Area /{units}$^2$\")\n    ax.set_ylabel(\"Count\")\n    return fig,ax\n\nfig,ax = plot_area_distribution_and_fit(patch_areas,\"mm\")\n\narea_studied = areas_data[sample][\"area_studied\"]\ntitle = f\"{sample}; n={sum(counts)}; area considered (convhull)={area_studied:.2f} mm$^2$;\\ntotal reflector area = {sum(patch_areas):.2f} mm$^2$; excluding contours with area < {min_reflector_area/(pix2mm ** 2)} px$^2$\"\nplt.title(title)\nsave_figure(os.path.join(\"imgs\",f\"{sample}-areas.png\"))\nplt.show()"]},{"cell_type":"markdown","id":"4f51c181-db2c-45b2-b4bf-8dafee9816f0","metadata":{},"source":["#### Aspect Ratio and Rotation\n\n"]},{"cell_type":"markdown","id":"bb97e75f-cd12-4b1d-88af-0ab35d8d5d90","metadata":{},"source":["The lengths of the long and short axes, as well as their ratio reveal information on the shape of reflector grains. Grain rotations may also reveal whether there's any preferred orientations present or not.\n\n"]},{"cell_type":"code","execution_count":1,"id":"1e99ef3f-8e4b-4e8d-93b4-6a5be6bad061","metadata":{},"outputs":[],"source":["def get_dimensions(contours):\n    ''' Extract minimum bounding rectangle dimensions from contours.\n\n    contours : list of contours\n\n    returns all_dimensions : list of lists containing dimesions of minimum bounding rectangles\n    '''\n    all_dimensions = []\n    for contour in contours:\n        center,dimensions,rotation = cv2.minAreaRect(contour)\n        all_dimensions.append(dimensions)\n    return all_dimensions\n\ndef aspect_ratio_hist(dimensions,bins=100):\n    ''' Plot histogram for aspect ratios from minimum bounding rectangle dimensions.\n\n    dimensions : list of lists containing dimesions of minimum bounding rectangles\n\n    returns fig, ax\n    '''\n    fig,ax = plt.subplots(constrained_layout=True)\n    # Extract short axes.\n    short_axes = list(map(min,dimensions))\n    # Extract long axes.\n    long_axes = list(map(max,dimensions))\n    # Compute grain aspect ratios.\n    aspect_ratios = np.array(long_axes)/np.array(short_axes)\n\n    # Plot histogram.\n    ax.hist(aspect_ratios,bins=bins,\n            histtype=\"step\",edgecolor=\"k\",label=\"Short\")\n\n    # Axes labelling.\n    ax.set_xlabel(\"Aspect Ratio\")\n    ax.set_ylabel(\"Count\")\n    # Set y axis to log scale.\n    ax.set_yscale(\"log\")\n    return fig,ax\n\ndimensions = get_dimensions(larger_contours)\nfig,ax = aspect_ratio_hist(dimensions)\nax.set_xlim([1,100])\nplt.title(title)\n# save_figure(f\"{sample}-aspect-ratios.png\")\nplt.show()"]},{"cell_type":"markdown","id":"d8451e41-ec9e-4a15-9121-d4fc9444c1e7","metadata":{},"source":["The closer to smaller numbers (i.e. 1) the aspect ratio is, the more equant the grain. It's expected that most grains of magnetite should be relatively equant. An aspect ratio of 5 means that the long axis of the minimum bounding rectangle around the grain is 5 times longer than the short axis of the same rectangle.\n\n"]},{"cell_type":"markdown","id":"cc847a62-22bc-485e-bedd-359a28757536","metadata":{},"source":["#### Reflector Area vs Distance to Nearest Neighbour\n\n"]},{"cell_type":"markdown","id":"2680482d-ba16-4e95-a197-55dd6bd9faa8","metadata":{},"source":["A lack of relation between grain size and distance to nearest neighbour was used by \\citet{Kretz1966} to infer that the size that a grain reaches is independent of its position in the rock relative to other grains of the same mineralogy, and that clusters of grains tend to have similar sizes to grains that are more isolated. To test whether this is the case for our samples, a plot of distance to nearest neighbour grain against grain area is created. Grain centroids are used to define nearest-neighbour distance.\n\n"]},{"cell_type":"code","execution_count":1,"id":"a6435043-8098-4693-aea2-6e1dece1ee7e","metadata":{},"outputs":[],"source":["from scipy.spatial import KDTree\n\ndef find_nn_distances(larger_contours,pix2mm):\n    ''' Find the nearest neighbour distance to each (larger) contour's centroid in order.\n\n    larger_contours : array of the larger contours (i.e. whose areas are always non-zero) in pixel units\n    pix2mm (numerical) : conversion factor between pixels and millimeters\n\n    returns distances (list of numericals) : nearest-neighbour distances\n    '''\n    # Unwrap contour coordinates.\n    larger_contours = [c[:,0,:] for c in larger_contours]\n    # Find centroids of these contours and halve coordinates to ensure units are 1 pixel = 1 micron.\n    centroids = [np.array(Polygon(c).centroid.xy).T[0]/2 for c in larger_contours]\n    # KD Tree that can be searched across.\n    tree = KDTree(centroids)\n    # Nearest-neighbour distances to each centroid in order.\n    distances = [tree.query(c,2)[0][1]*pix2mm for c in centroids]\n    return distances\n\ndef plot_area_vs_nearest_neighbour(areas,distances,max_area=0.05):\n    ''' Scatterplot reflector areas vs nearest-neighbour distances; create also histogram for nearest-neighbour distances aligned on the relevant axis.\n\n    areas (list of numericals) : reflector areas\n    distances (list of numericals) : list of nearest-neighbour distances corresponding to the reflectors described by areas\n\n    returns fig : Matplotlib Figure object\n    '''\n    fig = plt.figure(figsize=(6,6))\n    # Set up grid (1 row, 2 columns) that can be used to position axes.\n    # The left column plot (scatterplot) is 6 times wider than the right column plot (histogram).\n    gs = fig.add_gridspec(1,2,\n                          width_ratios=[6,1],\n                          hspace=0.1,\n                          wspace=0.1)\n\n    # Left column scatterplot.\n    units = \"mm\"\n    ax = fig.add_subplot(gs[0,0])\n    ax.scatter(areas,distances)\n    ax.set_xlabel(f\"Area /{units}$^2$\")\n    ax.set_ylabel(f\"Distance to nearest neighbour /{units}\")\n    ax.set_xlim([0,max_area])\n\n    # Right column histogram.\n    ax1 = fig.add_subplot(gs[0,1],sharey=ax)\n    ax1.tick_params(labelleft=False)\n    ax1.hist(distances,bins=50,orientation=\"horizontal\")\n    ax1.set_xlabel(\"Count\")\n\n    # Set figure title.\n    fig.suptitle(f\"{sample}\")\n    return fig\n\nnearest_neighbour_distances = find_nn_distances(larger_contours,pix2mm)\nplot_area_vs_nearest_neighbour(patch_areas,nearest_neighbour_distances)\nsave_figure(os.path.join(\"imgs\",f\"{sample}-area-nearest-neighbour.png\"))\nplt.show()"]},{"cell_type":"markdown","id":"67bc568f-7ffd-472c-ae1f-5645b6c7256d","metadata":{},"source":["### Extracting and Plotting Contour Area Slices\n\n"]},{"cell_type":"markdown","id":"b5c5b213-d2ae-42c7-bf0f-efc88f7ad573","metadata":{},"source":["Visualising which contours are within a certain grain size fraction can be useful. The method to look at a certain grain size fraction is captured by the code below, where a range of areas (min-max) in mm<sup>2</sup> is sliced into. Grains within the size range are coloured red.\n\n"]},{"cell_type":"code","execution_count":1,"id":"6d46a286-e26a-4967-a78d-a5bfce6835cf","metadata":{},"outputs":[],"source":["# Min max area (in mm2) range\narea_slice = [0.001,0.002]\n\n# Create boolean filter for patch areas within the specified range.\nminmax_filter = construct_minmax_filter(patch_areas,*area_slice)\n\n# Extract contours that have patch areas within the specified range.\nranged_contours = list_of_list_filter(contours,minmax_filter)\n\n# Path to reflector thresholded sample image.\nimg_path = os.path.join(rl_scan_folder,sample+\".png\")\n\nimg = cv2.imread(img_path)\n\n# Draw the patches that have patch areas within the min-max range.\n# NOTE: colors are BGR for CV2.\n[cv2.fillPoly(img,[np.reshape(c,(c.shape[0],2))],color=(0,0,255)) for c in ranged_contours]\n\ngrain_area_filtered = os.path.join(\"imgs\",f\"{sample}-{str(area_slice)}.jpg\")\nif not os.path.exists(grain_area_filtered) or FORCE_OVERWRITE:\n    cv2.imwrite(grain_area_filtered,img)\n\n# BGR to RGB.\nplt.imshow(img[:,:,::-1])\nplt.show()"]}],"metadata":{"org":null,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":5}
