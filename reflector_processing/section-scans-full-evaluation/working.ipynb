{"cells":[{"cell_type":"markdown","id":"2fb2f11f-1b57-4257-b1e7-5a9bf1e6f3e8","metadata":{},"source":"Reflector Area Processing - Testing\n===================================\n\n"},{"cell_type":"markdown","id":"93303304-9b98-49e2-841a-6f5e1255c141","metadata":{},"source":["To test the effect of manual gap filling, relevant functionality in notebook `../section-scans-full/working.org` was run for an thresholded image (`manual-M07B1-threshold.png`), and a thresholded image that was manually gap-filled (for grain reconstruction, where the interpretation of fractured grains originally being whole was on the basis of whether the gap appeared to be a fracture or not) (`manual-M07B1-threshold-redrawn.png`).\n\n-   Note: the original analysis of these two images was performed on 21 Nov 2023 with the conclusions:\n    -   Doesn't seem to be a huge difference in the distribution of grains <0.05 mm<sup>2</sup> area when reconstructing fractured grains - can still interpret this distribution as it's relatively robust.\n    -   However, there are significant differences in aspect ratios, maximum sizes etc.\n-   However, the discussions in `../section-scans-full/working.org` suggest that the amount of automatic gap filling may affect the observed distributions, and so further analysis is necessary.\n    -   This further analysis will be performed in `further_analysis.org`.\n\n"]},{"cell_type":"code","execution_count":1,"id":"88d04166-b9dc-41a3-8052-5c2b9938b529","metadata":{},"outputs":[],"source":["FORCE_OVERWRITE = False\n# Since this is testing the effect of manual gap-filling, not automatic gap filling is to be applied.\ndilate_erode = False\n\n####################################\n# Don't change anything below here #\n####################################\nif dilate_erode:\n    file_prepend = f\"modified-{dilate_erode}\"\nelse:\n    file_prepend = \"unmodified\"\n\n# Artificial alteration degree difference to permit comparison plotting.\nalteration_degree = {\"manual-M07B1-threshold\":0,\n                     \"manual-M07B1-threshold-redrawn\":1}\n# Text descriptions for each level of alteration.\nalteration_desc = {0:\"No redraw\",\n                   1:\"Redrawn\"}\n\nimport os\ndef save_figure(path):\n    ''' Check if an image containing figure output already exists, otherwise save that figure.\n\n    path (string) : path to save the figure to.\n\n    returns None\n    '''\n    if not os.path.exists(path) or FORCE_OVERWRITE:\n        plt.savefig(path,bbox_inches=\"tight\")\n    return\n\nimport pandas as pd\nimport json\n\nimport sys\nsys.path.insert(0,os.path.join(\"..\",\"section-scans-full\"))\nfrom util_funcs import *\nfrom plotting import *\n\nPLT = Plotter(alteration_degree,alteration_desc)\nplot_all = PLT.plot_all"]},{"cell_type":"markdown","id":"c2e8ed49-6b3a-4bdc-aa3b-b83bc8b16c0e","metadata":{},"source":["## Area Processing\n\n"]},{"cell_type":"markdown","id":"11d59703-7de3-42c2-b6c5-3a26afebf5d5","metadata":{},"source":["Using methods detailed in `../section_scans-example/working.org` (or its derivatives), captured by the class `AreaProcessor` in `area_process.py`\n\nExtracting area contours into .npy files and extracting areas into `areas.json`.\n\n-   `areas.json` is a very large file without linebreaks and so shouldn't be opened with text editors.\n\nAs an update/difference to the example processing notebook, the largest grain is also added to the data in `areas.json`.\n\n"]},{"cell_type":"code","execution_count":1,"id":"85b6c8d5-15cb-44b6-adfc-00981ef538c3","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"None"}],"source":["from area_processing import *\n\npix2mm = 1/1000\n\n# Folder containing thresholded samples (stored as .png).\n# Note: folder linking has been used - this is not the real path.\nsamples_dir = \"local_data\"\n\n# Load thresholded sample filenames from the folder.\nsamples = [k+\".png\" for k in alteration_degree]\n\n# Check if the areas datafile needs to be regenerated on the basis of missing file or request.\n# The areas datafile is specific to the processing pathway used to compute the areas (in terms of how much dilation-erosion is applied).\nif not os.path.exists(file_prepend + \"-areas.json\") or FORCE_OVERWRITE:\n    # Declare dictionary in which areas data will be stored.\n    areas_data = dict()\n    print(\"(Re)Generating areas.json ...\")\n    # Iterate through the samples with thresholded reflectors as identified above.\n    for sample in samples:\n        print(f\"Looking at {sample}\")\n        # Initiate area processor for the active sample, conversion pixels to mm conversion factor and desired processing pathway.\n        AP = AreaProcessor(os.path.join(samples_dir,sample),pix2mm,dilate_erode)\n        # Retrieve contours.\n        contours,larger_contours = AP.load_contours()\n        # Retrieve patch areas.\n        patch_areas,units = AP.find_areas()\n\n        # Find the largest grain area before filtering.\n        largest_grain = max(patch_areas)\n\n        # Size filtering (selecting only areas larger than 5 pixels, and smaller than 0.05 mm2).\n        min_reflector_area = 5 * pix2mm**2 # mm2\n        max_reflector_area = 0.05 # mm2\n\n        # Construct boolean filter based on grain size.\n        size_filter = construct_minmax_filter(patch_areas,min_reflector_area,max_reflector_area)\n        # Filter the patch areas using this boolean filter.\n        patch_areas = patch_areas[size_filter]\n\n        # Filter \"small\" and \"large\" contours using this boolean filter.\n        contours = list_of_list_filter(contours,size_filter)\n        larger_contours = list_of_list_filter(larger_contours,size_filter)\n\n        # Check if the folder for storing filtered data in is present, and if not, create this folder.\n        filtered_data_dir = \"filtered_data\"\n        if not os.path.exists(filtered_data_dir):\n            os.mkdir(filtered_data_dir)\n        # Save the filtered contours if their savefiles aren't already present.\n        base_data_file = os.path.join(filtered_data_dir,f\"{file_prepend}-{sample}\")\n        if not os.path.exists(base_data_file + \".npy\"):\n            np.save(base_data_file + \".npy\",np.array(contours,dtype=object))\n            np.save(base_data_file + \"-larger.npy\",np.array(larger_contours,dtype=object))\n\n        # Extract sample name from sample filename.\n        sample = sample.replace(\".png\",\"\")\n        # Construct dictionary to place sample-specific area data.\n        areas_data[sample] = dict()\n        # Add reflector patch areas.\n        areas_data[sample][\"patch_areas\"] = list(patch_areas)\n        # Add the area considered when looking at patch areas.\n        areas_data[sample][\"area_studied\"] = AP.area_studied()\n        # Add the largest grain observed.\n        areas_data[sample][\"largest_grain\"] = largest_grain\n    # Save all samples' areas data for this processing pathway.\n    with open(file_prepend + \"-areas.json\",\"w\") as outfile:\n        json.dump(areas_data,outfile)\nelse:\n    print(f\"Loading {file_prepend}-areas.json\")\n    # Load data from persistent storage.\n    with open(file_prepend + \"-areas.json\") as infile:\n        areas_data = json.load(infile)\nprint(\"... complete\")"]},{"cell_type":"markdown","id":"300c1bd0-596a-462b-a1d8-4329fa5c6588","metadata":{},"source":["### Area Distribution Plotting\n\n"]},{"cell_type":"markdown","id":"fa93635b-a3a6-4732-9f62-9ccfd07c9d06","metadata":{},"source":["On the plots, the area range (x-axis) is hardcoded (to between 0 and 0.05 mm<sup>2</sup>).\n\n"]},{"cell_type":"code","execution_count":1,"id":"dadf3511-d4ef-48ba-bbae-f4299f53d981","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"None"}],"source":["fig = plot_all(PLT.area_distros,file_prepend,figsize=(18,8))\nfig.suptitle(\"Area Distributions\")\nsave_figure(os.path.join(\"imgs\",file_prepend + \"-area-distro.png\"))\nplt.show()"]},{"cell_type":"markdown","id":"71c772f1-2196-49c0-a1ed-8eebf427475c","metadata":{},"source":["There's not a huge difference in the relative shapes of the distributions - the redrawn version is slightly broader.\n\n"]},{"cell_type":"markdown","id":"a1738d81-5853-4b85-8b47-4f8a80c6dca8","metadata":{},"source":["## Reflector Area vs Nearest Neighbour Distance\n\n"]},{"cell_type":"markdown","id":"9e5af883-165d-4d0d-a8cb-8750c47ca8fa","metadata":{},"source":["On the plots, the area range (x-axis) is hardcoded (to between 0 and 0.05 mm<sup>2</sup>), and the nearest neighbour distance is hardcoded (to between 0 and 1 mm).\n\n"]},{"cell_type":"code","execution_count":1,"id":"fca93ca3-96e3-4ceb-97e3-3d0767569c48","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"None"}],"source":["fig = plot_all(PLT.area_vs_nn_dist,file_prepend,figsize=(18,8))\nfig.suptitle(\"Area vs Nearest Neighbour Distance\")\nsave_figure(os.path.join(\"imgs\",file_prepend + \"-area-nn-dist.png\"))\nplt.show()"]},{"cell_type":"markdown","id":"7eccd0ed-0a91-472f-ab6f-104ae407c75e","metadata":{},"source":["The scatter plots and histogram shapes appear quite different, but the histograms peak is in the same position.\n\n-   Therefore the change in histogram peak position with increasing dilation-erosion in the data is likely a false effect.\n\n"]},{"cell_type":"markdown","id":"ddf18ddb-32bc-4b8f-8032-4cc684ea7659","metadata":{},"source":["## Reflector Aspect Ratios\n\n"]},{"cell_type":"markdown","id":"cc4479e7-f39d-418e-95b8-4511f8c5666b","metadata":{},"source":["On the plots, the aspect ratio range (x-axis) is hardcoded (to between 0 and 20).\n\n"]},{"cell_type":"code","execution_count":1,"id":"23e192a5-640b-40b7-b4f6-288f8a4b0686","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"None"}],"source":["fig = plot_all(PLT.aspect_ratio_distros,file_prepend,figsize=(18,8))\nfig.suptitle(\"Aspect Ratio Distributions\")\nsave_figure(os.path.join(\"imgs\",file_prepend + \"-aspect-ratios.png\"))\nplt.show()"]},{"cell_type":"markdown","id":"597252d9-eba9-4b19-b07b-ad8991b407ac","metadata":{},"source":["Redrawing seems to have shifted average aspect ratios closer to 1 - i.e. grains more equant.\n\n-   Note however that aspect ratios were discovered to be unsuitable for interpretation anyway so this is not a hugely relevant inference.\n\n"]},{"cell_type":"markdown","id":"e40bbbdb-e41b-4f2a-909c-743c16422c02","metadata":{},"source":["## Generalised Section Properties Processing\n\n"]},{"cell_type":"markdown","id":"62c42dd4-b6eb-43fe-beb2-e39d0b437c56","metadata":{},"source":["The generalised section properties (table [1](#org6352b77)) are section-specific (as opposed to grain-specific) properties that were initially though to be useful to compare between sections.\n\n\n| Property|Description|Units|\n|---|---|---|\n| <code>convhull</code>|area studied|mm<sup>2</sup>|\n| <code>n</code>|number of reflectors considered||\n| <code>total_area</code>|total area covered by reflectors|mm<sup>2</sup>|\n| <code>largest</code>|area of largest reflector|mm<sup>2</sup>|\n| <code>curve_fit</code>|area distribution fit parameters||\n| <code>alteration</code>|quantitative alteration degree||\n\n"]},{"cell_type":"code","execution_count":1,"id":"064d42b7-c2e4-4e77-a1a9-dac2c2d6433a","metadata":{},"outputs":[],"source":["# Check if the summaries datafile needs to be regenerated on the basis of missing file or request.\nif not os.path.exists(file_prepend + \"-summary.csv\") or FORCE_OVERWRITE:\n    data = dict()\n    # Iterate through samples and their area data.\n    for sample,sample_area_data in areas_data.items():\n        # Load patch areas.\n        patch_areas = sample_area_data[\"patch_areas\"]\n        # Load area studied.\n        area_studied = sample_area_data[\"area_studied\"]\n        # Load size of largest grain.\n        largest_grain = sample_area_data[\"largest_grain\"]\n        # Compute distribution parameters for patch areas.\n        counts,_,midpoints = bin_values(patch_areas,0.05,100)\n\n        # Construct summary dataframe for each sample.\n        data[sample] = {\"convhull\":area_studied, # study area\n                        \"n\":len(patch_areas), # number of discrete reflectors after filtering\n                        \"total_area\":sum(patch_areas), # area of reflectors after filtering\n                        \"largest\":largest_grain, # largest continuous reflector patch area\n                        \"curve_fit\":fit_exp_log_y(midpoints,counts)}\n\n        # Degree of alteration assigned to each section.\n        # Note: alteration_degree is imported from plotting.py\n        try:\n            data[sample][\"alteration\"] = alteration_degree[sample]\n        except KeyError:\n            pass\n\n    # Convert dictionary to pandas dataframe.\n    df = pd.DataFrame.from_dict(data,orient=\"index\")\n    # Save pandas dataframe to .csv file.\n    df.to_csv(file_prepend + \"-summary.csv\")"]},{"cell_type":"markdown","id":"9622447c-1dcc-4cd6-8805-ab50c828004c","metadata":{},"source":["### Comparison Plotting\n\n"]},{"cell_type":"markdown","id":"f4c26c41-f75f-46ef-a11b-bf2ecbbcbd33","metadata":{},"source":["After obtaining this data, comparisons can be plotted.\n\n-   In some cases, derived parameters (that are normalised to the area studied) are more useful for comparing between sections.\n    -   Reflector coverage area &rarr; reflector coverage percentage.\n    -   Reflector count &rarr; reflector number density.\n-   Only sections that are partially (0) or heavily (1) altered will be considered in the comparison.\n\n"]},{"cell_type":"code","execution_count":1,"id":"23e04675-03d8-4a39-9305-bb03dd196704","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"None"}],"source":["# Force load from .csv file so that list processing is standardised.\ndf = pd.read_csv(file_prepend + \"-summary.csv\",index_col=0)\n# Derived parameters that are more logical to compare between sections.\ndf[\"reflector_percentage\"] = df[\"total_area\"]/df[\"convhull\"]\ndf[\"number_density\"] = df[\"n\"]/df[\"convhull\"]\n\n# Look at only sections that have an alteration index of 1 (heavy) or 0 (partly).\ndf = df[(df[\"alteration\"]==1) | (df[\"alteration\"]==0)]\n\ncurve_fits = np.array(json.loads(\"[\" + \",\".join(df[\"curve_fit\"]) + \"]\"))\n\nprint(\"\\t\"*4 + \" [No redraw\\tManual Redraw]\")\nprint(\"Largest grain /mm^2:\\t\\t\", df[\"largest\"].to_numpy())\nprint(\"Reflector number density /mm^-2:\",df[\"number_density\"].to_numpy())\nprint(\"Reflector coverage /%:\\t\\t\", df[\"reflector_percentage\"].to_numpy())\nprint(\"a/n:\\t\\t\\t\\t\",curve_fits[:,0]/df[\"n\"].to_numpy())\nprint(\"b:\\t\\t\\t\\t\", curve_fits[:,1])"]},{"cell_type":"markdown","id":"a119e7e8-7886-448f-bd27-fb0bc1c09a46","metadata":{},"source":["Comparing these differences to the observed differences across samples of different degrees of alteration (manually copied from the other notebook since Jupyter notebook seems unable to search for files outside of it's parent directory even if trusted):\n\n<table>\n<tr>\n<td><img src=\"imgs/unmodified-refl-param-comparison.png\"></td>\n<td><img src=\"imgs/unmodified-area_fit_param_comp.png\"></td>\n</tr>\n</table>\n\nThe difference between no redraw and manually redrawn seems relatively large for all metrics except the $b$ parameter in the distribution, hence differences in relative area distribution shapes should be relatively robust.\n\n"]}],"metadata":{"org":null,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":5}
